{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad3de3e2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40bc651",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# read the text file\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4165a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding the text and cleaning it\n",
    "file_path = 'training_text.txt'\n",
    "text = read_text_file(file_path)\n",
    "\n",
    "text = text.strip(\"\\ufeff\")\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f20b27ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270151\n",
      "In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in\n"
     ]
    }
   ],
   "source": [
    "# length of text\n",
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73953d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !$()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXY[]abcdefghijklmnopqrstuvwxyzçéêô —‘’“”…\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "# checking all the characters used in the text\n",
    "char = sorted(list(set(text)))\n",
    "vocab_size = len(char)\n",
    "print(''.join(char))\n",
    "print(vocab_size)\n",
    "eval_iters = 200\n",
    "max_iters = 10000\n",
    "num_emb = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a880489a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 63, 63]\n",
      "foo\n"
     ]
    }
   ],
   "source": [
    "# hence we need to tokenize the vocab ourselves\n",
    "stoi = { ch:i for i, ch in enumerate(char)}\n",
    "itos = { i:ch for i, ch in enumerate(char)}\n",
    "\n",
    "def encode(str):\n",
    "    return [stoi[c] for c in str]\n",
    "\n",
    "def decode(data):\n",
    "    return \"\".join(itos[c] for c in data)\n",
    "\n",
    "foo = encode(\"foo\")\n",
    "print(foo)\n",
    "print(decode(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd3c1d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30, 62, 0, 61, 73, 0, 73, 63, 69, 62, 55, 53, 66, 0, 49, 62, 52, 0, 61, 63, 66, 53, 0, 70, 69, 60, 62, 53, 66, 49, 50, 60, 53, 0, 73, 53, 49, 66, 67, 0, 61, 73, 0, 54, 49, 68, 56, 53, 66, 0, 55, 49, 70, 53, 0, 61, 53, 0, 67, 63, 61, 53, 0, 49, 52, 70, 57, 51, 53, 0, 68, 56, 49, 68, 0, 30, 82, 70, 53, 0, 50, 53, 53, 62, 0, 68, 69, 66, 62, 57, 62, 55, 0, 63, 70, 53, 66, 0, 57, 62]\n",
      "In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in\n"
     ]
    }
   ],
   "source": [
    "# testing encode with my own functions\n",
    "test_encode = encode(text[:100])\n",
    "print(test_encode)\n",
    "print(decode(test_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53db67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([270151]) torch.int64\n",
      "tensor([30, 62,  0, 61, 73,  0, 73, 63, 69, 62, 55, 53, 66,  0, 49, 62, 52,  0,\n",
      "        61, 63, 66, 53,  0, 70, 69, 60, 62, 53, 66, 49, 50, 60, 53,  0, 73, 53,\n",
      "        49, 66, 67,  0, 61, 73,  0, 54, 49, 68, 56, 53, 66,  0, 55, 49, 70, 53,\n",
      "         0, 61, 53,  0, 67, 63, 61, 53,  0, 49, 52, 70, 57, 51, 53,  0, 68, 56,\n",
      "        49, 68,  0, 30, 82, 70, 53,  0, 50, 53, 53, 62,  0, 68, 69, 66, 62, 57,\n",
      "        62, 55,  0, 63, 70, 53, 66,  0, 57, 62,  0, 61, 73,  0, 61, 57, 62, 52,\n",
      "         0, 53, 70, 53, 66,  0, 67, 57, 62, 51, 53,  8,  0,  0, 83, 44, 56, 53,\n",
      "        62, 53, 70, 53, 66,  0, 73, 63, 69,  0, 54, 53, 53, 60,  0, 60, 57, 59,\n",
      "        53,  0, 51, 66, 57, 68, 57, 51, 57, 74, 57, 62, 55,  0, 49, 62, 73, 63,\n",
      "        62, 53,  6, 84,  0, 56, 53,  0, 68, 63, 60, 52,  0, 61, 53,  6,  0, 83,\n",
      "        58, 69, 67, 68,  0, 66, 53, 61, 53, 61, 50, 53, 66,  0, 68, 56, 49, 68,\n",
      "         0, 49, 60, 60,  0, 68, 56, 53,  0, 64, 53, 63, 64, 60, 53,  0, 57, 62,\n",
      "         0, 68, 56, 57, 67,  0, 71, 63, 66, 60, 52,  0, 56, 49, 70, 53, 62, 82,\n",
      "        68,  0, 56, 49, 52,  0, 68, 56, 53,  0, 49, 52, 70, 49, 62, 68, 49, 55,\n",
      "        53, 67,  0, 68, 56, 49, 68,  0, 73, 63, 69, 82, 70, 53,  0, 56, 49, 52,\n",
      "         8, 84,  0,  0, 29, 53,  0, 52, 57, 52, 62, 82, 68,  0, 67, 49, 73,  0,\n",
      "        49, 62, 73,  0, 61, 63, 66, 53,  6,  0, 50, 69, 68,  0, 71, 53, 82, 70,\n",
      "        53,  0, 49, 60, 71, 49, 73, 67,  0, 50, 53, 53, 62,  0, 69, 62, 69, 67,\n",
      "        69, 49, 60, 60, 73,  0, 51, 63, 61, 61, 69, 62, 57, 51, 49, 68, 57, 70,\n",
      "        53,  0, 57, 62,  0, 49,  0, 66, 53, 67, 53, 66, 70, 53, 52,  0, 71, 49,\n",
      "        73,  6,  0, 49, 62, 52,  0, 30,  0, 69, 62, 52, 53, 66, 67, 68, 63, 63,\n",
      "        52,  0, 68, 56, 49, 68,  0, 56, 53,  0, 61, 53, 49, 62, 68,  0, 49,  0,\n",
      "        55, 66, 53, 49, 68,  0, 52, 53, 49, 60,  0, 61, 63, 66, 53,  0, 68, 56,\n",
      "        49, 62,  0, 68, 56, 49, 68,  8,  0, 30, 62,  0, 51, 63, 62, 67, 53, 65,\n",
      "        69, 53, 62, 51, 53,  6,  0, 30, 82, 61,  0, 57, 62, 51, 60, 57, 62, 53,\n",
      "        52,  0, 68, 63,  0, 66, 53, 67, 53, 66, 70, 53,  0, 49, 60, 60,  0, 58,\n",
      "        69, 52, 55, 53, 61, 53, 62, 68, 67,  6,  0, 49,  0, 56, 49, 50, 57, 68,\n",
      "         0, 68, 56, 49, 68,  0, 56, 49, 67,  0, 63, 64, 53, 62])\n"
     ]
    }
   ],
   "source": [
    "# now encoding the entire text\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf788128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training data and validation data\n",
    "n = int(0.9*len(data))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0a18753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([30, 62,  0, 61, 73,  0, 73, 63, 69])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up block size\n",
    "block_size = 8\n",
    "train[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b60abbe1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# setting batch size\n",
    "batch_size = 4\n",
    "\n",
    "# function for getting a batch of random blocks within data, set my batch_size\n",
    "def get_batch(split):\n",
    "    if split == \"train\":\n",
    "        data = train\n",
    "    else:\n",
    "        data = val\n",
    "\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "# estimate function that estimates the average loss in splits\n",
    "def estimate():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in [\"train\", \"val\"]:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for i in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[i] = loss.item()\n",
    "        out[split] = losses.mean() # collecting the average\n",
    "    model.train()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6aa405b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[68, 63,  0, 24, 56, 57, 51, 49],\n",
      "        [ 0, 51, 63, 63, 60,  0, 68, 56],\n",
      "        [62,  0, 68, 56, 53,  0, 67, 63],\n",
      "        [53,  8,  0, 40, 63, 61, 53, 68]])\n",
      "tensor([[63,  0, 24, 56, 57, 51, 49, 55],\n",
      "        [51, 63, 63, 60,  0, 68, 56, 49],\n",
      "        [ 0, 68, 56, 53,  0, 67, 63, 49],\n",
      "        [ 8,  0, 40, 63, 61, 53, 68, 57]])\n"
     ]
    }
   ],
   "source": [
    "# collecting inputs and targets from the training data\n",
    "# targets used for creating the loss function later on\n",
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07f01b5f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# class for the language model\n",
    "class BigramLM(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, num_emb)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, num_emb)\n",
    "        self.lm_head = nn.Linear(num_emb, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        B,T = inputs.shape\n",
    "\n",
    "        token_emb = self.token_embedding_table(inputs) # batch, time, channel\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=inputs.device))\n",
    "\n",
    "        T = min(T, self.block_size)\n",
    "        x = token_emb + pos_emb\n",
    "\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # need to reformat BTC into B*C, T for loss to work\n",
    "            b, t, c = logits.shape\n",
    "            logits = logits.view(b*t, c)\n",
    "\n",
    "            # targets are in B T and needs to be B*T\n",
    "            targets = targets.view(b*t)\n",
    "\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "    \n",
    "    def generate(self, inputs, number):\n",
    "        for _ in range(number):\n",
    "            inputs_cropped = inputs[:, -self.block_size:]\n",
    "            logits, loss = self(inputs_cropped)\n",
    "            logits = logits[:, -1, :]\n",
    "            prob = F.softmax(logits, 1)\n",
    "            inputs_next = torch.multinomial(prob, 1)\n",
    "            inputs = torch.cat((inputs, inputs_next), 1)\n",
    "\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64f88242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 86])\n",
      "tensor(4.5258, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Initialize and move the model to the correct device\n",
    "model = BigramLM().to(device)\n",
    "\n",
    "logits, loss = model(xb.to(device), yb.to(device))\n",
    "\n",
    "print(logits.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85047eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making a pytorch optimizer object\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212097b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Loss = 4.760985374450684\n",
      "Step 100: Loss = 3.538388252258301\n",
      "Step 200: Loss = 2.91546630859375\n",
      "Step 300: Loss = 2.7562575340270996\n",
      "Step 400: Loss = 2.7423250675201416\n",
      "Step 500: Loss = 2.8735148906707764\n",
      "Step 600: Loss = 2.4632015228271484\n",
      "Step 700: Loss = 2.4777352809906006\n",
      "Step 800: Loss = 2.5186984539031982\n",
      "Step 900: Loss = 2.490985631942749\n",
      "Step 1000: Loss = 2.520765542984009\n",
      "Step 1100: Loss = 2.6084511280059814\n",
      "Step 1200: Loss = 2.3419439792633057\n",
      "Step 1300: Loss = 2.422070264816284\n",
      "Step 1400: Loss = 2.639904499053955\n",
      "Step 1500: Loss = 2.5703036785125732\n",
      "Step 1600: Loss = 2.474938154220581\n",
      "Step 1700: Loss = 2.483727216720581\n",
      "Step 1800: Loss = 2.562690496444702\n",
      "Step 1900: Loss = 2.522002696990967\n",
      "Step 2000: Loss = 2.3571014404296875\n",
      "Step 2100: Loss = 2.453205108642578\n",
      "Step 2200: Loss = 2.375826120376587\n",
      "Step 2300: Loss = 2.4197616577148438\n",
      "Step 2400: Loss = 2.391451358795166\n",
      "Step 2500: Loss = 2.521249532699585\n",
      "Step 2600: Loss = 2.5391042232513428\n",
      "Step 2700: Loss = 2.3694231510162354\n",
      "Step 2800: Loss = 2.450044631958008\n",
      "Step 2900: Loss = 2.46158766746521\n",
      "Step 3000: Loss = 2.272045135498047\n",
      "Step 3100: Loss = 2.4636008739471436\n",
      "Step 3200: Loss = 2.375002384185791\n",
      "Step 3300: Loss = 2.391935348510742\n",
      "Step 3400: Loss = 2.2549021244049072\n",
      "Step 3500: Loss = 2.458278179168701\n",
      "Step 3600: Loss = 2.363478899002075\n",
      "Step 3700: Loss = 2.5455210208892822\n",
      "Step 3800: Loss = 2.374514579772949\n",
      "Step 3900: Loss = 2.3712334632873535\n",
      "Step 4000: Loss = 2.4680228233337402\n",
      "Step 4100: Loss = 2.521069288253784\n",
      "Step 4200: Loss = 2.4320151805877686\n",
      "Step 4300: Loss = 2.347524881362915\n",
      "Step 4400: Loss = 2.388500452041626\n",
      "Step 4500: Loss = 2.472489356994629\n",
      "Step 4600: Loss = 2.4863903522491455\n",
      "Step 4700: Loss = 2.445444345474243\n",
      "Step 4800: Loss = 2.406188726425171\n",
      "Step 4900: Loss = 2.3776702880859375\n",
      "Step 5000: Loss = 2.4263389110565186\n",
      "Step 5100: Loss = 2.4172089099884033\n",
      "Step 5200: Loss = 2.3414177894592285\n",
      "Step 5300: Loss = 2.510305166244507\n",
      "Step 5400: Loss = 2.693361282348633\n",
      "Step 5500: Loss = 2.4277024269104004\n",
      "Step 5600: Loss = 2.417823553085327\n",
      "Step 5700: Loss = 2.336311101913452\n",
      "Step 5800: Loss = 2.4512312412261963\n",
      "Step 5900: Loss = 2.3855035305023193\n",
      "Step 6000: Loss = 2.2905945777893066\n",
      "Step 6100: Loss = 2.318592071533203\n",
      "Step 6200: Loss = 2.456423282623291\n",
      "Step 6300: Loss = 2.4616823196411133\n",
      "Step 6400: Loss = 2.447154998779297\n",
      "Step 6500: Loss = 2.4133362770080566\n",
      "Step 6600: Loss = 2.343376636505127\n",
      "Step 6700: Loss = 2.358771800994873\n",
      "Step 6800: Loss = 2.439607620239258\n",
      "Step 6900: Loss = 2.4153923988342285\n",
      "Step 7000: Loss = 2.4074018001556396\n",
      "Step 7100: Loss = 2.233802318572998\n",
      "Step 7200: Loss = 2.4718737602233887\n",
      "Step 7300: Loss = 2.476815938949585\n",
      "Step 7400: Loss = 2.4414634704589844\n",
      "Step 7500: Loss = 2.3934576511383057\n",
      "Step 7600: Loss = 2.551175832748413\n",
      "Step 7700: Loss = 2.4078073501586914\n",
      "Step 7800: Loss = 2.2817955017089844\n",
      "Step 7900: Loss = 2.422776699066162\n",
      "Step 8000: Loss = 2.3627777099609375\n",
      "Step 8100: Loss = 2.4588353633880615\n",
      "Step 8200: Loss = 2.4412927627563477\n",
      "Step 8300: Loss = 2.5461220741271973\n",
      "Step 8400: Loss = 2.5399601459503174\n",
      "Step 8500: Loss = 2.2913763523101807\n",
      "Step 8600: Loss = 2.491051435470581\n",
      "Step 8700: Loss = 2.3626508712768555\n",
      "Step 8800: Loss = 2.4066481590270996\n",
      "Step 8900: Loss = 2.5042083263397217\n",
      "Step 9000: Loss = 2.2290990352630615\n",
      "Step 9100: Loss = 2.408137083053589\n",
      "Step 9200: Loss = 2.3934006690979004\n",
      "Step 9300: Loss = 2.310638666152954\n",
      "Step 9400: Loss = 2.3586246967315674\n",
      "Step 9500: Loss = 2.411322832107544\n",
      "Step 9600: Loss = 2.374443292617798\n",
      "Step 9700: Loss = 2.5574405193328857\n",
      "Step 9800: Loss = 2.392622470855713\n",
      "Step 9900: Loss = 2.4999234676361084\n",
      "2.319817304611206\n"
     ]
    }
   ],
   "source": [
    "# increasing batch size and setting a loop to evaluate loss\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(max_iters):\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        # losses = estimate()\n",
    "        print(f\"Step {i}: Loss = {loss.item()}\")\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb.to(device), yb.to(device))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e888fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cath s  awan Gache beren me befo de ler wng, te be anan’they mowapif d toled allofreail. horot omolk—hely,” I Nomatolnthouneng, styos od cotind rmare rang ch mer Toter athenin’ss mewhisladeter. h aut sal. d ime hie’sendyours  In tche sureerce. boredn s Weng me ashe’siney, erey shin Mivit! thed  wapu\n"
     ]
    }
   ],
   "source": [
    "input = torch.zeros((1, 1), dtype=torch.long).to(device)\n",
    "print(decode(model.generate(input, 300)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8181bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication and softmax\n",
    "\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "out = wei @ x\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b0730a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ff513c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1d411c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 32])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# self attention\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # B, T, 16\n",
    "q = query(x)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1)\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=-1)\n",
    "# out = wei @ x\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61febb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8569, 0.1431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5426, 0.3957, 0.0617, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.7973, 0.0452, 0.1281, 0.0295, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.0184, 0.0808, 0.0182, 0.8508, 0.0318, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5542, 0.3354, 0.0113, 0.0065, 0.0119, 0.0808, 0.0000, 0.0000],\n",
       "        [0.1774, 0.1786, 0.0395, 0.1391, 0.3335, 0.0742, 0.0578, 0.0000],\n",
       "        [0.1507, 0.1743, 0.1649, 0.0092, 0.0655, 0.1764, 0.1420, 0.1169]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2fe3e47a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
