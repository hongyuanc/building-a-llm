{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import torch\n",
    "import tiktoken\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the text file\n",
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feeding the text and cleaning it\n",
    "file_path = 'training_text.txt'\n",
    "text = read_text_file(file_path)\n",
    "\n",
    "text = text.strip(\"\\ufeff\")\n",
    "text = text.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in\n"
     ]
    }
   ],
   "source": [
    "# length of text\n",
    "print(len(text))\n",
    "print(text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " !$()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXY[]abcdefghijklmnopqrstuvwxyzçéêô —‘’“”…\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "# checking all the characters used in the text\n",
    "char = sorted(list(set(text)))\n",
    "vocab_size = len(char)\n",
    "print(''.join(char))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bringing in tiktoken's tokenizer\n",
    "\n",
    "# THIS WILL NOT WORK\n",
    "\n",
    "enc = tiktoken.get_encoding(\"gpt2\")\n",
    "enc.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31373]\n",
      "[818, 616, 7099, 290, 517, 8826, 812, 616, 2988, 2921, 502, 617, 5608, 326, 314, 447, 247, 303, 587, 6225, 625, 287]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with encoding and decoding; it works now, but note that we only have\n",
    "# a vocab_size of 85\n",
    "encode = enc.encode(\"hello\")\n",
    "print(encode)\n",
    "enc.decode(encode)\n",
    "\n",
    "encode1 = enc.encode(text[:100])\n",
    "print(encode1)\n",
    "enc.decode(encode1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54, 63, 63]\n",
      "foo\n"
     ]
    }
   ],
   "source": [
    "# hence we need to tokenize the vocab ourselves\n",
    "stoi = { ch:i for i, ch in enumerate(char)}\n",
    "itos = { i:ch for i, ch in enumerate(char)}\n",
    "\n",
    "def encode(str):\n",
    "    return [stoi[c] for c in str]\n",
    "\n",
    "def decode(str):\n",
    "    return \"\".join([itos[c] for c in str])\n",
    "\n",
    "foo = encode(\"foo\")\n",
    "print(foo)\n",
    "print(decode(foo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([71784]) torch.int64\n",
      "tensor([  818,   616,  7099,   290,   517,  8826,   812,   616,  2988,  2921,\n",
      "          502,   617,  5608,   326,   314,   447,   247,   303,   587,  6225,\n",
      "          625,   287,   616,  2000,  1683,  1201,    13,   220,   564,   250,\n",
      "        28877,   345,  1254,   588, 26816,  2687,    11,   447,   251,   339,\n",
      "         1297,   502,    11,   564,   250,  3137,  3505,   326,   477,   262,\n",
      "          661,   287,   428,   995,  4398,   447,   247,    83,   550,   262,\n",
      "        13391,   326,   345,   447,   247,   303,   550,    13,   447,   251,\n",
      "          220,   679,  1422,   447,   247,    83,   910,   597,   517,    11,\n",
      "          475,   356,   447,   247,   303,  1464,   587, 23708,  1316, 43058,\n",
      "          287,   257, 10395,   835,    11,   290,   314,  7247,   326,   339,\n",
      "         4001,   257,  1049,  1730,   517,   621,   326,    13,   554, 12921,\n",
      "           11,   314,   447,   247,    76, 19514,   284, 11515,   477,  2553,\n",
      "        43547,    11,   257,  7947,   326,   468,  4721,   510,   867, 11040,\n",
      "          299,  6691,   284,   502,   290,   635,   925,   502,   262,  3117,\n",
      "          286,   407,   257,  1178,  9298,   275,  2850,    13,   383, 18801,\n",
      "         2000,   318,  2068,   284,  4886,   290, 10199,  2346,   284,   428,\n",
      "         3081,   618,   340,  3568,   287,   257,  3487,  1048,    11,   290,\n",
      "          523,   340,  1625,   546,   326,   287,  4152,   314,   373, 21218,\n",
      "          306,  5371,   286,   852,   257, 14971,    11,   780,   314,   373,\n",
      "         1953,    88,   284,   262,  3200, 18522,    82,   286,  4295,    11,\n",
      "         6439,  1450,    13,  4042,   286,   262,  1013, 44845,   547,  5576,\n",
      "         2917,   960,    69, 37971,   314,   423,   730,  3916,  3993,    11,\n",
      "          662, 19596,   341,    11,   393,   257, 12524,   443, 21319,   618,\n",
      "          314,  6939,   416,   617, 40016, 29033,  1051,   326,   281, 16584,\n",
      "        16084,   373,   627, 35598,   319,   262, 17810,    26,   329,   262,\n",
      "        16584, 19111,   286,  1862,  1450,    11,   393,   379,  1551,   262,\n",
      "         2846,   287,   543,   484,  4911,   606,    11,   389,  3221, 42054,\n",
      "         2569,   290,  1667,   445,   416,  3489, 18175,   507,    13,  1874,\n",
      "        14344,  2553, 43547,   318,   257,  2300,   286, 15541,  2911,    13,\n",
      "          314,   716,   991,   257,  1310,  7787,   286,  4814,  1223,   611,\n",
      "          314,  6044,   326,    11,   355,   616,  2988,  3013, 21963, 29735,\n",
      "         5220,    11,   290,   314,  3013, 21963, 29735,  9585,    11,   257,\n",
      "         2565,   286,   262,  7531,   875,  3976,   318,  1582,   344,  3353,\n",
      "          503, 21149,   453,   379,  4082,    13,   220,   843,    11,   706,\n",
      "        40776,   428,   835,   286,   616, 15621,    11,   314,  1282,   284,\n",
      "          262, 13938,   326,   340,   468,   257,  4179,    13, 28579,   743,\n",
      "          307,  9393,   319,   262,  1327,  3881,   393,   262,  9583, 48962,\n",
      "          956,    11,   475,   706,   257,  1728,   966,   314,   836,   447,\n",
      "          247,    83,  1337,   644,   340,   447,   247,    82,  9393,   319,\n",
      "           13,  1649,   314,  1625,   736,   422,   262,  3687,   938, 23608,\n",
      "          314,  2936,   326,   314,  2227,   262,   995,   284,   307,   287,\n",
      "         8187,   290,   379,   257,  3297,   286,  6573,  3241,  8097,    26,\n",
      "          314,  2227,   645,   517, 16352,   516,  2859, 42394,   351, 21929,\n",
      "        41226,   274,   656,   262,  1692,  2612,    13,  5514,   402,  1381,\n",
      "         1525,    11,   262,   582,   508,  3607,   465,  1438,   284,   428,\n",
      "         1492,    11,   373, 13068,   422,   616,  6317,   960,    38,  1381,\n",
      "         1525,    11,   508,  7997,  2279,   329,   543,   314,   423,   281,\n",
      "        35290, 40987,    13,  1002,  8806,   318,   281,   555, 25826,  2168,\n",
      "          286,  4388, 24621,    11,   788,   612,   373,  1223, 18857,   546,\n",
      "          683,    11,   617, 25556, 14233,   284,   262, 10497,   286,  1204])\n"
     ]
    }
   ],
   "source": [
    "# now encoding the entire text\n",
    "data = torch.tensor(enc.encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data into training data and validation data\n",
    "n = int(0.9*len(data))\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 818,  616, 7099,  290,  517, 8826,  812,  616, 2988])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up block size\n",
    "block_size = 8\n",
    "train[:block_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting batch size\n",
    "batch_size = 4\n",
    "\n",
    "# function for getting a batch of random blocks within data, set my batch_size\n",
    "def get_batch(split):\n",
    "    if split == \"train\":\n",
    "        data = train\n",
    "    else:\n",
    "        data = val\n",
    "\n",
    "    ix = torch.randint(len(data) - batch_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
    "    y = torch.stack([data[i + 1: i + block_size + 1] for i in ix])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1541,  6590, 10802,   286,   262,  3715,    13,   220],\n",
      "        [  835,   284,  1194,  9082,    11,   281, 35639, 37968],\n",
      "        [  262,  2479,   286, 38741,   290,   379,   262,  2176],\n",
      "        [  607,  6576,    11,   290,  2063,   281,  1711,  1568]])\n",
      "tensor([[ 6590, 10802,   286,   262,  3715,    13,   220,   317],\n",
      "        [  284,  1194,  9082,    11,   281, 35639, 37968,   286],\n",
      "        [ 2479,   286, 38741,   290,   379,   262,  2176,  2589],\n",
      "        [ 6576,    11,   290,  2063,   281,  1711,  1568,    11]])\n"
     ]
    }
   ],
   "source": [
    "# collecting inputs and targets from the training data\n",
    "# targets used for creating the loss function later on\n",
    "xb, yb = get_batch(\"train\")\n",
    "\n",
    "print(xb)\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class for the language model\n",
    "class BigramLM(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logits = self.token_embedding_table(inputs) # batch, time, channel tensor\n",
    "\n",
    "        return logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m BigramLM(vocab_size)\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(output\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 9\u001b[0m, in \u001b[0;36mBigramLM.forward\u001b[0;34m(self, inputs, targets)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, targets):\n\u001b[0;32m----> 9\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_embedding_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# batch, time, channel tensor\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model = BigramLM(vocab_size)\n",
    "\n",
    "output = model(xb, yb)\n",
    "\n",
    "print(output.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
